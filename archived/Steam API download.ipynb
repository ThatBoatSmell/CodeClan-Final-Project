{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fe11ff",
   "metadata": {},
   "source": [
    "## This code was taken from Nik Davis's blogposts about pulling steam store data from steam's API. Thanks, Nik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb84b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is D897-BC08\n",
      "\n",
      " Directory of C:\\Users\\CodeClan\\Desktop\\CodeClan\\CodeClan-Final-Project\n",
      "\n",
      "13/06/2023  10:17    <DIR>          .\n",
      "13/06/2023  10:17    <DIR>          ..\n",
      "11/06/2023  14:08                66 .gitattributes\n",
      "11/06/2023  14:08               720 .gitignore\n",
      "13/06/2023  10:05    <DIR>          .ipynb_checkpoints\n",
      "12/06/2023  15:27    <DIR>          clean_data\n",
      "13/06/2023  10:03               218 CodeClan-Final-Project.Rproj\n",
      "12/06/2023  18:39        13,611,574 looking at them.nb.html\n",
      "12/06/2023  18:39            15,819 looking at them.Rmd\n",
      "12/06/2023  18:39    <DIR>          raw_data\n",
      "13/06/2023  10:17            22,793 Steam API download.ipynb\n",
      "               6 File(s)     13,651,190 bytes\n",
      "               5 Dir(s)  127,932,112,896 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4e9ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import csv\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# customisations - ensure tables show all columns\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682574b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I believe this is error handing?\n",
    "def get_request(url, parameters=None):\n",
    "    \"\"\"Return json-formatted response of a get request using optional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "    parameters : {'parameter': 'value'}\n",
    "        parameters to pass as part of get request\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    json_data\n",
    "        json-formatted response (dict-like)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url=url, params=parameters)\n",
    "    except SSLError as s:\n",
    "        print('SSL Error:', s)\n",
    "        \n",
    "        for i in range(5, 0, -1):\n",
    "            print('\\rWaiting... ({})'.format(i), end='')\n",
    "            time.sleep(1)\n",
    "        print('\\rRetrying.' + ' '*10)\n",
    "        \n",
    "        # recusively try again\n",
    "        return get_request(url, parameters)\n",
    "    \n",
    "    if response:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # response is none usually means too many requests. Wait and try again \n",
    "        print('No response, waiting 10 seconds...')\n",
    "        time.sleep(10)\n",
    "        print('Retrying.')\n",
    "        return get_request(url, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3bec5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid                       name\n",
       "0     10             Counter-Strike\n",
       "1     20      Team Fortress Classic\n",
       "2     30              Day of Defeat\n",
       "3     40         Deathmatch Classic\n",
       "4     50  Half-Life: Opposing Force"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://steamspy.com/api.php\"\n",
    "parameters = {\"request\": \"all\"}\n",
    "\n",
    "# request 'all' from steam spy and parse into dataframe\n",
    "json_data = get_request(url, parameters=parameters)\n",
    "steam_spy_all = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "\n",
    "# generate sorted app_list from steamspy data\n",
    "app_list = steam_spy_all[['appid', 'name']].sort_values('appid').reset_index(drop=True)\n",
    "\n",
    "# export disabled to keep consistency across download sessions\n",
    "# app_list.to_csv('../data/download/app_list.csv', index=False)\n",
    "\n",
    "# instead read from stored csv\n",
    "app_list = pd.read_csv('app_list.csv')\n",
    "\n",
    "# display first few rows\n",
    "app_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_data(start, stop, parser, pause):\n",
    "    \"\"\"Return list of app data generated from parser.\n",
    "    \n",
    "    parser : function to handle request\n",
    "    \"\"\"\n",
    "    app_data = []\n",
    "    \n",
    "    # iterate through each row of app_list, confined by start and stop\n",
    "    for index, row in app_list[start:stop].iterrows():\n",
    "        print('Current index: {}'.format(index), end='\\r')\n",
    "        \n",
    "        appid = row['appid']\n",
    "        name = row['name']\n",
    "\n",
    "        # retrive app data for a row, handled by supplied parser, and append to list\n",
    "        data = parser(appid, name)\n",
    "        app_data.append(data)\n",
    "\n",
    "        time.sleep(pause) # prevent overloading api with requests\n",
    "    \n",
    "    return app_data\n",
    "\n",
    "\n",
    "def process_batches(parser, app_list, download_path, data_filename, index_filename,\n",
    "                    columns, begin=0, end=-1, batchsize=100, pause=1):\n",
    "    \"\"\"Process app data in batches, writing directly to file.\n",
    "    \n",
    "    parser : custom function to format request\n",
    "    app_list : dataframe of appid and name\n",
    "    download_path : path to store data\n",
    "    data_filename : filename to save app data\n",
    "    index_filename : filename to store highest index written\n",
    "    columns : column names for file\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    begin : starting index (get from index_filename, default 0)\n",
    "    end : index to finish (defaults to end of app_list)\n",
    "    batchsize : number of apps to write in each batch (default 100)\n",
    "    pause : time to wait after each api request (defualt 1)\n",
    "    \n",
    "    returns: none\n",
    "    \"\"\"\n",
    "    print('Starting at index {}:\\n'.format(begin))\n",
    "    \n",
    "    # by default, process all apps in app_list\n",
    "    if end == -1:\n",
    "        end = len(app_list) + 1\n",
    "    \n",
    "    # generate array of batch begin and end points\n",
    "    batches = np.arange(begin, end, batchsize)\n",
    "    batches = np.append(batches, end)\n",
    "    \n",
    "    apps_written = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    for i in range(len(batches) - 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = batches[i]\n",
    "        stop = batches[i+1]\n",
    "        \n",
    "        app_data = get_app_data(start, stop, parser, pause)\n",
    "        \n",
    "        rel_path = os.path.join(download_path, data_filename)\n",
    "        \n",
    "        # writing app data to file\n",
    "        with open(rel_path, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns, extrasaction='ignore')\n",
    "            \n",
    "            for j in range(3,0,-1):\n",
    "                print(\"\\rAbout to write data, don't stop script! ({})\".format(j), end='')\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            writer.writerows(app_data)\n",
    "            print('\\rExported lines {}-{} to {}.'.format(start, stop-1, data_filename), end=' ')\n",
    "            \n",
    "        apps_written += len(app_data)\n",
    "        \n",
    "        idx_path = os.path.join(download_path, index_filename)\n",
    "        \n",
    "        # writing last index to file\n",
    "        with open(idx_path, 'w') as f:\n",
    "            index = stop\n",
    "            print(index, file=f)\n",
    "            \n",
    "        # logging time taken\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        \n",
    "        batch_times.append(time_taken)\n",
    "        mean_time = statistics.mean(batch_times)\n",
    "        \n",
    "        est_remaining = (len(batches) - i - 2) * mean_time\n",
    "        \n",
    "        remaining_td = dt.timedelta(seconds=round(est_remaining))\n",
    "        time_td = dt.timedelta(seconds=round(time_taken))\n",
    "        mean_td = dt.timedelta(seconds=round(mean_time))\n",
    "        \n",
    "        print('Batch {} time: {} (avg: {}, remaining: {})'.format(i, time_td, mean_td, remaining_td))\n",
    "            \n",
    "    print('\\nProcessing batches complete. {} apps written'.format(apps_written))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34134d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index(download_path, index_filename):\n",
    "    \"\"\"Reset index in file to 0.\"\"\"\n",
    "    rel_path = os.path.join(download_path, index_filename)\n",
    "    \n",
    "    with open(rel_path, 'w') as f:\n",
    "        print(0, file=f)\n",
    "        \n",
    "\n",
    "def get_index(download_path, index_filename):\n",
    "    \"\"\"Retrieve index from file, returning 0 if file not found.\"\"\"\n",
    "    try:\n",
    "        rel_path = os.path.join(download_path, index_filename)\n",
    "\n",
    "        with open(rel_path, 'r') as f:\n",
    "            index = int(f.readline())\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        index = 0\n",
    "        \n",
    "    return index\n",
    "\n",
    "\n",
    "def prepare_data_file(download_path, filename, index, columns):\n",
    "    \"\"\"Create file and write headers if index is 0.\"\"\"\n",
    "    if index == 0:\n",
    "        rel_path = os.path.join(download_path, filename)\n",
    "\n",
    "        with open(rel_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69cb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_steam_request(appid, name):\n",
    "    \"\"\"Unique parser to handle data from Steam Store API.\n",
    "    \n",
    "    Returns : json formatted data (dict-like)\n",
    "    \"\"\"\n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    json_app_data = json_data[str(appid)]\n",
    "    \n",
    "    if json_app_data['success']:\n",
    "        data = json_app_data['data']\n",
    "    else:\n",
    "        data = {'name': name, 'steam_appid': appid}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "# Set file parameters\n",
    "download_path = '../data/download'\n",
    "steam_app_data = 'steam_app_data.csv'\n",
    "steam_index = 'steam_index.txt'\n",
    "\n",
    "steam_columns = [\n",
    "    'type', 'name', 'steam_appid', 'required_age', 'is_free', 'controller_support',\n",
    "    'dlc', 'detailed_description', 'about_the_game', 'short_description', 'fullgame',\n",
    "    'supported_languages', 'header_image', 'website', 'pc_requirements', 'mac_requirements',\n",
    "    'linux_requirements', 'legal_notice', 'drm_notice', 'ext_user_account_notice',\n",
    "    'developers', 'publishers', 'demos', 'price_overview', 'packages', 'package_groups',\n",
    "    'platforms', 'metacritic', 'reviews', 'categories', 'genres', 'screenshots',\n",
    "    'movies', 'recommendations', 'achievements', 'release_date', 'support_info',\n",
    "    'background', 'content_descriptors'\n",
    "]\n",
    "\n",
    "# Overwrites last index for demonstration (would usually store highest index so can continue across sessions)\n",
    "reset_index(download_path, steam_index)\n",
    "\n",
    "# Retrieve last index downloaded from file\n",
    "index = get_index(download_path, steam_index)\n",
    "\n",
    "# Wipe or create data file and write headers if index is 0\n",
    "prepare_data_file(download_path, steam_app_data, index, steam_columns)\n",
    "\n",
    "# Set end and chunksize for demonstration - remove to run through entire app list\n",
    "process_batches(\n",
    "    parser=parse_steam_request,\n",
    "    app_list=app_list,\n",
    "    download_path=download_path,\n",
    "    data_filename=steam_app_data,\n",
    "    index_filename=steam_index,\n",
    "    columns=steam_columns,\n",
    "    begin=index,\n",
    "    end=10,\n",
    "    batchsize=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6468c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect downloaded data\n",
    "pd.read_csv('../data/download/steam_app_data.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_steamspy_request(appid, name):\n",
    "    \"\"\"Parser to handle SteamSpy API data.\"\"\"\n",
    "    url = \"https://steamspy.com/api.php\"\n",
    "    parameters = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "# set files and columns\n",
    "download_path = '../data/download'\n",
    "steamspy_data = 'steamspy_data.csv'\n",
    "steamspy_index = 'steamspy_index.txt'\n",
    "\n",
    "steamspy_columns = [\n",
    "    'appid', 'name', 'developer', 'publisher', 'score_rank', 'positive',\n",
    "    'negative', 'userscore', 'owners', 'average_forever', 'average_2weeks',\n",
    "    'median_forever', 'median_2weeks', 'price', 'initialprice', 'discount',\n",
    "    'languages', 'genre', 'ccu', 'tags'\n",
    "]\n",
    "\n",
    "reset_index(download_path, steamspy_index)\n",
    "index = get_index(download_path, steamspy_index)\n",
    "\n",
    "# Wipe data file if index is 0\n",
    "prepare_data_file(download_path, steamspy_data, index, steamspy_columns)\n",
    "\n",
    "process_batches(\n",
    "    parser=parse_steamspy_request,\n",
    "    app_list=app_list,\n",
    "    download_path=download_path, \n",
    "    data_filename=steamspy_data,\n",
    "    index_filename=steamspy_index,\n",
    "    columns=steamspy_columns,\n",
    "    begin=index,\n",
    "    end=20,\n",
    "    batchsize=5,\n",
    "    pause=0.3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
