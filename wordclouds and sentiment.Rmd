---
title: "WORDS WORDS WORDS"
output: html_notebook
---
# This is quite a resource hog - I wouldn't recommend running this all at once
```{r}
library(tidyverse)
library(tidytext)
library(textdata)
library(ggwordcloud)
```

```{r}
sampled_reviews <- read_csv("raw_data/sample_of_steam_reviews.csv")
```

```{r}
palette_pos <-  c("#01295F", "#849324","#FFB30F", "#FD151B")
palette_neg <- c("#FF8506", "#291211", "#F8CF0F", "#4C1600")
```


```{r}
sampled_reviews <- sampled_reviews %>% 
  mutate(review_score = case_when(
    review_score == 1 ~ "Positive",
    review_score == -1 ~ "Negative"
  )) %>% 
  select(-review_votes)
```
```{r}
sampled_reviews %>% 
  glimpse()
```
```{r}
game_stop_words <- tibble(
  word = c("game", "gameplay", "time", "played", "play", "playing","games", "review", "access", "www.youtube.com", "www.youtube.co.uk") # lets try doing n-grams before populating this
)

early_access_words <- tibble(
  word = c("early", "access", "www.youtube.com", "youtube")
)
```

slap in this bad boy to try and avoid having a load of game names in the wordcloud

```{r}
game_stop_bigrams <- sampled_reviews %>% 
  select(app_name) %>% 
  unnest_tokens(bigram, app_name, token = "ngrams", n = 2) %>% 
  drop_na()
```


```{r}
positive_sample_words <- sampled_reviews %>% 
  filter(review_score == "Positive") %>% 
   unnest_tokens(output = word, input = review_text) %>% 
  anti_join(stop_words) %>% 
  anti_join(game_stop_words) %>% 
  count(word) %>% 
  arrange(desc(n))
```

```{r}
negative_sample_words <- sampled_reviews %>% 
  filter(review_score == "Negative") %>% 
   unnest_tokens(output = word, input = review_text) %>% 
  anti_join(stop_words) %>% 
  anti_join(game_stop_words) %>% 
  count(word) %>% 
  arrange(desc(n)) %>% 
  inner_join(get_sentiments("bing")) %>% 
  filter(sentiment == "negative") 
```
```{r}
get_sentiments("nrc") %>% 
  distinct(sentiment)
```



```{r}
sampled_reviews %>% 
  mutate(pizza = str_detect(review_text, "pizzaboy")) %>% 
  filter(pizza == TRUE)
```


```{r}
ggwordcloud(words = positive_sample_words$word, freq = positive_sample_words$n, random.color = TRUE, colors =  palette_pos, min.freq = 5)
```
```{r}
ggwordcloud(words = negative_sample_words$word, freq = negative_sample_words$n, random.color = TRUE, colors =  palette_neg, min.freq = 5)
```
 
```{r}
positive_sample_bigrams <- sampled_reviews %>% 
  filter(review_score == "Positive") %>% 
  unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE) %>%  # count bigrams
  separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
  anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
  anti_join(stop_words, join_by("word2" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
  anti_join(early_access_words, join_by("word1" == "word")) %>%
  anti_join(early_access_words, join_by("word2" == "word")) %>% 
  drop_na() %>% 
  unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
  anti_join(game_stop_bigrams)
```

```{r}
ggwordcloud(words = positive_sample_bigrams$bigram, freq = positive_sample_bigrams$n, random.color = TRUE, colors = palette_pos, min.freq = 50)
```

```{r}
ggwordcloud(words = positive_sample_bigrams$bigram, freq = positive_sample_bigrams$n, random.color = TRUE, colors =  palette_pos, min.freq = 80)
```

```{r}
negative_sample_bigrams <- sampled_reviews %>% 
  filter(review_score == "Negative") %>% 
  unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE) %>%  # count bigrams
  separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
  anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
  anti_join(stop_words, join_by("word2" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
  anti_join(early_access_words, join_by("word1" == "word")) %>%
  anti_join(early_access_words, join_by("word2" == "word")) %>% 
  drop_na() %>% 
  unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
  anti_join(game_stop_bigrams)
```

```{r}
ggwordcloud(words = negative_sample_bigrams$bigram, freq = negative_sample_bigrams$n, random.color = TRUE, colors =  palette_neg, min.freq = 15)
```

Lets try slapping sentiment analysis on these and filter only by those with a negative sentiment?

```{r}
test_negative_sentiments <- sampled_reviews %>% 
  filter(review_score == "Negative") %>% 
  unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE) %>%  # count bigrams
  separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
  anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
  anti_join(stop_words, join_by("word2" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
  anti_join(early_access_words, join_by("word1" == "word")) %>%
  anti_join(early_access_words, join_by("word2" == "word")) %>% 
  drop_na() %>% 
  inner_join(get_sentiments("bing"), join_by("word1" == "word")) %>% 
  inner_join(get_sentiments("bing"), join_by("word2" == "word")) %>% 
  mutate(total_sentiment = case_when(
    sentiment.x == "positive" & sentiment.y == "negative" ~ "negative",
    sentiment.x == "negative" & sentiment.y == "negative" ~ "negative",
    sentiment.x == "positive" & sentiment.y == "positive" ~ "positive",
    sentiment.x == "negative" & sentiment.y == "positive" ~ "positive",
    TRUE ~ "this shouldn't appear"
  )) %>% 
  select(-sentiment.x, -sentiment.y) %>% 
  filter(total_sentiment == "negative") %>% 
  drop_na() %>% 
  unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
  anti_join(game_stop_bigrams)

```
```{r}
test_negative_sentiments %>% 
  mutate(length = nchar(bigram)) %>% 
  arrange(desc(length))
```

```{r}
get_sentiments("bing")
```
```{r}
ggwordcloud(words = test_negative_sentiments $bigram, freq = test_negative_sentiments $n, random.color = TRUE, colors =  palette_neg, min.freq = 2)
```

```{r}
negative_sample_sentiment <- sampled_reviews %>% 
  filter(review_score == "Negative") %>% 
   unnest_tokens(output = word, input = review_text) %>% 
  anti_join(stop_words) %>% 
  anti_join(game_stop_words) %>% 
  count(word) %>% 
  inner_join(get_sentiments("bing")) %>% 
  arrange(desc(n)) %>% 
  filter(sentiment == "negative")
```
```{r}
ggwordcloud(words = negative_sample_sentiment$word, freq = negative_sample_sentiment$n, random.color = TRUE, colors =  palette_neg, min.freq = 5)

ggsave("Visualisations/negative_steam_words.png", dpi = 500)
```

```{r}
positive_sample_sentiment <- sampled_reviews %>% 
  filter(review_score == "Positive") %>% 
   unnest_tokens(output = word, input = review_text) %>% 
  anti_join(stop_words) %>% 
  anti_join(game_stop_words) %>% 
  count(word) %>% 
  inner_join(get_sentiments("bing")) %>% 
  arrange(desc(n)) %>% 
  filter(sentiment == "positive")
```

```{r}
ggwordcloud(words = positive_sample_sentiment$word, freq = positive_sample_sentiment$n, random.color = TRUE, colors =  palette_pos, min.freq = 5)
```
```{r}
# What about trigrams?

# Not really much different - Not gonna bother

# sampled_reviews %>% 
#   filter(review_score == "Negative") %>% 
#   unnest_tokens(trigram, review_text, token = "ngrams", n = 3) %>% 
#   count(trigram, sort = TRUE) %>%  # count bigrams
#   separate(trigram, into = c("word1", "word2", "word3"), sep = " ") %>% # split bigrams into two seperate columns
#   # anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
#   # anti_join(stop_words, join_by("word2" == "word")) %>% 
#   # anti_join(stop_words, join_by("word2" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
#   anti_join(early_access_words, join_by("word1" == "word")) %>%
#   anti_join(early_access_words, join_by("word2" == "word")) %>% 
#   anti_join(early_access_words, join_by("word3" == "word"))
#   #drop_na() %>% 
#   inner_join(get_sentiments("bing"), join_by("word1" == "word")) %>% 
#   inner_join(get_sentiments("bing"), join_by("word2" == "word")) %>% 
#   inner_join(get_sentiments("bing"), join_by("word3" == "word")) %>% 
#   mutate(total_sentiment = case_when(
#     sentiment.x == "positive" & sentiment.y == "negative" ~ "negative",
#     sentiment.x == "negative" & sentiment.y == "negative" ~ "negative",
#     sentiment.x == "positive" & sentiment.y == "positive" ~ "positive",
#     sentiment.x == "negative" & sentiment.y == "positive" ~ "positive",
#     TRUE ~ "this shouldn't appear"
#   )) %>% 
#   select(-sentiment.x, -sentiment.y) %>% 
#   filter(total_sentiment == "negative") %>% 
#   drop_na() %>% 
#   unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
#   anti_join(game_stop_bigrams)

```

```{r}
# what if we combine the negative bigrams with the negative words?
test_negative_sentiments %>% 
  rename("word" = "bigram", "sentiment" = "total_sentiment") %>% 
  bind_rows(negative_sample_words) %>% 
  arrange(desc(n))

# Single words completely dominate the bigrams.  Maybe take a sample of 1000 random words?Although i suppose that kind of defeats the purpose
```


```{r}
# What if we take the negative bigrams, but don't filter out the stop words?

sampled_reviews %>% 
  filter(review_score == "Negative") %>% 
  unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE) %>%  # count bigrams
  separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
  # anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
  # anti_join(stop_words, join_by("word2" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
  anti_join(early_access_words, join_by("word1" == "word")) %>%
  anti_join(early_access_words, join_by("word2" == "word")) %>% 
  drop_na() %>% 
  inner_join(get_sentiments("bing"), join_by("word1" == "word")) %>% 
  inner_join(get_sentiments("bing"), join_by("word2" == "word")) %>% 
  mutate(total_sentiment = case_when(
    sentiment.x == "positive" & sentiment.y == "negative" ~ "negative",
    sentiment.x == "negative" & sentiment.y == "negative" ~ "negative",
    sentiment.x == "positive" & sentiment.y == "positive" ~ "positive",
    sentiment.x == "negative" & sentiment.y == "positive" ~ "positive",
    TRUE ~ "this shouldn't appear"
  )) %>% 
  select(-sentiment.x, -sentiment.y) %>% 
  filter(total_sentiment == "negative") %>% 
  drop_na() %>% 
  unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
  anti_join(game_stop_bigrams)
```



I think i just need more negative reviews. Time to dive back into the steam reviews dataset

Ok now i have a million negative reviews and a million positive reviews

Lets read them in and see if i break everything

```{r}
negative_reviews <- read_csv("raw_data/negative_steam_reviews.csv")
positive_reviews <- read_csv("raw_data/positive_steam_reviews.csv")
```

```{r}
game_stop_bigrams_negative <- negative_reviews %>% 
  select(app_name) %>% 
  unnest_tokens(bigram, app_name, token = "ngrams", n = 2) %>% 
  drop_na()

game_stop_bigrams_positive <- positive_reviews %>% 
  select(app_name) %>% 
  unnest_tokens(bigram, app_name, token = "ngrams", n = 2) %>% 
  drop_na()
```



```{r}
# seeing as we now have two separate datasets, we don't really need to keep anything except the reviews
negative_reviews <- negative_reviews %>% 
  select(-review_votes, -review_score, -app_id)
```

```{r}
positive_reviews <- positive_reviews %>% 
   select(-review_votes, -review_score, -app_id)
```

```{r}
# Saved so we don't have to run this every time

# test_negative_sentiments <- negative_reviews %>% 
#   unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
#   count(bigram, sort = TRUE) %>%  # count bigrams
#   separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
#   anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
#   anti_join(stop_words, join_by("word2" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
#   anti_join(early_access_words, join_by("word1" == "word")) %>%
#   anti_join(early_access_words, join_by("word2" == "word")) %>% 
#   drop_na() %>% 
#   inner_join(get_sentiments("bing"), join_by("word1" == "word")) %>% 
#   inner_join(get_sentiments("bing"), join_by("word2" == "word")) %>% 
#   mutate(total_sentiment = case_when(
#     sentiment.x == "positive" & sentiment.y == "negative" ~ "negative",
#     sentiment.x == "negative" & sentiment.y == "negative" ~ "negative",
#     sentiment.x == "positive" & sentiment.y == "positive" ~ "positive",
#     sentiment.x == "negative" & sentiment.y == "positive" ~ "positive",
#     TRUE ~ "this shouldn't appear"
#   )) %>% 
#   select(-sentiment.x, -sentiment.y) %>% 
#   filter(total_sentiment == "negative") %>% 
#   drop_na() %>% 
#   unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
#   anti_join(game_stop_bigrams_negative)
```
```{r}
# write_csv(test_negative_sentiments, "clean_data/negative_reviews_ready_for_clouding.csv")
```

```{r}
test_negative_sentiments <- read_csv("clean_data/negative_reviews_ready_for_clouding.csv")
```


```{r}
ggwordcloud(words = test_negative_sentiments$bigram, freq = test_negative_sentiments$n, random.color = TRUE, colors =  palette_neg, min.freq = 40)

#ggsave("Visualisations/negative_steam_bigrams.png", dpi = 500)
```
```{r}
# Saved for the same reason

# test_positive_sentiments <- positive_reviews %>% 
#   unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
#   count(bigram, sort = TRUE) %>%  # count bigrams
#   separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
#   anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
#   anti_join(stop_words, join_by("word2" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
#   anti_join(early_access_words, join_by("word1" == "word")) %>%
#   anti_join(early_access_words, join_by("word2" == "word")) %>% 
#   drop_na() %>% 
#   inner_join(get_sentiments("bing"), join_by("word1" == "word")) %>% 
#   inner_join(get_sentiments("bing"), join_by("word2" == "word")) %>% 
#   mutate(total_sentiment = case_when(
#     sentiment.x == "positive" & sentiment.y == "negative" ~ "negative",
#     sentiment.x == "negative" & sentiment.y == "negative" ~ "negative",
#     sentiment.x == "positive" & sentiment.y == "positive" ~ "positive",
#     sentiment.x == "negative" & sentiment.y == "positive" ~ "positive",
#     TRUE ~ "this shouldn't appear"
#   )) %>% 
#   select(-sentiment.x, -sentiment.y) %>% 
#   filter(total_sentiment == "positive") %>% 
#   drop_na() %>% 
#   unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
#   anti_join(game_stop_bigrams_positive)
```

```{r}
test_positive_sentiments <- read_csv("clean_data/positive_reviews_ready_for_clouding.csv")
```


```{r}
ggwordcloud(words = test_positive_sentiments$bigram, freq = test_positive_sentiments$n, random.color = TRUE, colors =  palette_pos, min.freq = 50)

# ggsave("Visualisations/postive_steam_bigrams.png", dpi = 500)
```
```{r}
# write_csv(test_positive_sentiments, "clean_data/positive_reviews_ready_for_clouding.csv")
```
```{r}
positive_review_words <- positive_reviews %>% 
  unnest_tokens(output = word, input = review_text) %>% 
  anti_join(stop_words) %>% 
  anti_join(game_stop_words) %>% 
  count(word) %>% 
  inner_join(get_sentiments("bing")) %>% 
  arrange(desc(n)) %>% 
  filter(sentiment == "positive")
```

```{r}
ggwordcloud(words = positive_review_words$word, freq = positive_review_words$n, random.color = TRUE, colors =  palette_pos, min.freq = 90)

# ggsave("Visualisations/postive_steam_words.png", dpi = 500)
```

```{r}
# testing a version without sentiment, just to show comparisons
negative_no_sentiment <- negative_reviews %>% 
  unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE) %>%  # count bigrams
  separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
  anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
  anti_join(stop_words, join_by("word2" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
  anti_join(early_access_words, join_by("word1" == "word")) %>%
  anti_join(early_access_words, join_by("word2" == "word")) %>% 
  drop_na() %>% 
  unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) 

```

```{r}
ggwordcloud(words = negative_no_sentiment$bigram, freq = negative_no_sentiment$n, random.color = TRUE, colors =  palette_neg, min.freq = 50)
```

```{r}
positive_no_sentiment <- positive_reviews %>% 
  unnest_tokens(bigram, review_text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE) %>%  # count bigrams
  separate(bigram, into = c("word1", "word2"), sep = " ") %>% # split bigrams into two seperate columns
  anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
  anti_join(stop_words, join_by("word2" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
 # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
  anti_join(early_access_words, join_by("word1" == "word")) %>%
  anti_join(early_access_words, join_by("word2" == "word")) %>% 
  drop_na() %>% 
  unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) 
```

```{r}
ggwordcloud(words = positive_no_sentiment$bigram, freq = positive_no_sentiment$n, random.color = TRUE, colors =  palette_pos, min.freq = 1000)
```

```{r}
# 
# positive_no_sentiment_tri <- positive_reviews %>% 
#   unnest_tokens(trigram, review_text, token = "ngrams", n = 3) %>% 
#   count(trigram, sort = TRUE) %>%  # count bigrams
#   separate(trigram, into = c("word1", "word2", "word3"), sep = " ") %>% # split bigrams into two seperate columns
#   anti_join(stop_words, join_by("word1" == "word")) %>%  # check if word1 of bigram is a stop word
#   anti_join(stop_words, join_by("word2" == "word")) %>% 
#   anti_join(stop_words, join_by("word3" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word1" == "word")) %>% 
#  # anti_join(game_stop_words, join_by("word2" == "word")) %>% 
#   anti_join(early_access_words, join_by("word1" == "word")) %>%
#   anti_join(early_access_words, join_by("word2" == "word")) %>% 
#   anti_join(early_access_words, join_by("word3" == "word")) %>% 
#   drop_na() %>% 
#   unite(col = "bigram", word1:word2, sep = " ", remove = TRUE) %>% 
#   unite(col = "trigram", bigram:word3, sep = " ", remove = TRUE)
```

```{r}
ggwordcloud(words = positive_no_sentiment_tri$trigram, freq = positive_no_sentiment_tri$n, random.color = TRUE, colors =  palette_pos, min.freq = 100)
```
well that was a waste of time
